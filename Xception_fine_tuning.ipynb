{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir, makedirs, walk\n",
    "from os.path import isdir, isfile, join, exists, expanduser\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "from itertools import compress\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, BatchNormalization, deserialize\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import xception\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.callbacks import *\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 299\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_folder      = 'data/train/'\n",
    "valid_folder      = 'data/validation/'\n",
    "test_folder       = 'data/test'\n",
    "weights_folder    = 'models/'\n",
    "\n",
    "bottleneck_features_train_npy = 'bottleneck_features_train.npy'\n",
    "bottleneck_features_valid_npy = 'bottleneck_features_valid.npy'\n",
    "bottleneck_labels_train_npy = 'bottleneck_labels_train.npy'\n",
    "bottleneck_labels_valid_npy = 'bottleneck_labels_valid.npy'\n",
    "\n",
    "top_model_epochs = 50\n",
    "complete_model_epochs = 50\n",
    "\n",
    "augmented_images_multiply_factor = 3\n",
    "\n",
    "# Create weights folder to save model weights\n",
    "if not exists(weights_folder):\n",
    "    makedirs(weights_folder)\n",
    "    \n",
    "ext = '.jpg'\n",
    "classes = [fldr for fldr in listdir(train_folder) if isdir(join(train_folder, fldr))]\n",
    "num_classes = len(classes)\n",
    "train_samples = sum([len(files) for r, d, files in walk(train_folder)])\n",
    "valid_samples = sum([len(files) for r, d, files in walk(valid_folder)])\n",
    "test_samples = sum([len(files) for r, d, files in walk(test_folder)])\n",
    "\n",
    "print (\"Classes: {}, Training samples: {}, Validation samples: {}, Test samples: {}\".format(num_classes, train_samples, valid_samples, test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(16, 16))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(3, 3), axes_pad=0.05)\n",
    "\n",
    "for i, cls in enumerate(np.random.choice(classes, 9)):\n",
    "    ax = grid[i]\n",
    "    img_file = np.random.choice(listdir(join(train_folder, cls)))\n",
    "    img = image.load_img(join(train_folder, cls, img_file), target_size=(INPUT_SIZE,INPUT_SIZE))\n",
    "    img = image.img_to_array(img)\n",
    "    ax.imshow(img / 255.)\n",
    "    ax.text(10, 200, 'LABEL: %s' % cls, color='k', backgroundcolor='w', alpha=0.8)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting [Keras example](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) for Xception model with multiclass classification\n",
    "\n",
    "1. Create base model and save bottleneck features\n",
    "2. Train top-model with bottleneck features\n",
    "3. Setup data to flow from directory with augmentation\n",
    "4. Fine tune base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create base model and save bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating wrapper for input preprocessing from https://nbviewer.jupyter.org/gist/embanner/6149bba89c174af3bfd69537b72bca74 \n",
    "def preprocess_input_xception(x):\n",
    "    \"\"\"Wrapper around keras.applications.xception.preprocess_input()\n",
    "    to make it compatible for use with keras.preprocessing.image.ImageDataGenerator's\n",
    "    `preprocessing_function` argument.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : a numpy 3darray (a single image to be preprocessed)\n",
    "    \n",
    "    Note we cannot pass keras.applications.xception.preprocess_input()\n",
    "    directly to to keras.preprocessing.image.ImageDataGenerator's\n",
    "    `preprocessing_function` argument because the former expects a\n",
    "    4D tensor whereas the latter expects a 3D tensor. Hence the\n",
    "    existence of this wrapper.\n",
    "    \n",
    "    Returns a numpy 3darray (the preprocessed image).\n",
    "    \n",
    "    \"\"\"\n",
    "    X = np.expand_dims(x, axis=0)\n",
    "    X = preprocess_input(X)\n",
    "    return X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = xception.Xception(weights='imagenet', include_top=False, input_tensor=Input(shape=(INPUT_SIZE,INPUT_SIZE,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(bottleneck_features_train_npy):\n",
    "    # Set up data generator for bottleneck features - only need preprocessing (no augmentation)\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input_xception)\n",
    "\n",
    "    # Generate bottleneck features for training data, and accompanying labels\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_folder,\n",
    "        target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='sparse',\n",
    "        shuffle=False)\n",
    "\n",
    "    bottleneck_features_train = base_model.predict_generator(generator, verbose = 1)\n",
    "    np.save(bottleneck_features_train_npy, bottleneck_features_train)\n",
    "\n",
    "    bottleneck_labels_train = to_categorical(generator.classes, num_classes=num_classes)\n",
    "    np.save(bottleneck_labels_train_npy, bottleneck_labels_train)\n",
    "    \n",
    "else:\n",
    "    bottleneck_features_train = np.load(bottleneck_features_train_npy)\n",
    "    bottleneck_labels_train = np.load(bottleneck_labels_train_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(bottleneck_features_valid_npy):\n",
    "    # Generate bottleneck features for validation data, and accompanying labels\n",
    "    generator = datagen.flow_from_directory(\n",
    "        valid_folder,\n",
    "        target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='sparse',\n",
    "        shuffle=False)\n",
    "\n",
    "    bottleneck_features_valid = base_model.predict_generator(generator, verbose = 1)\n",
    "    np.save(bottleneck_features_valid_npy, bottleneck_features_valid)\n",
    "\n",
    "    bottleneck_labels_valid = to_categorical(generator.classes, num_classes=num_classes)\n",
    "    np.save(bottleneck_labels_valid_npy, bottleneck_labels_valid)\n",
    "\n",
    "else:\n",
    "    bottleneck_features_valid = np.load(bottleneck_features_valid_npy)\n",
    "    bottleneck_labels_valid = np.load(bottleneck_labels_valid_npy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create and train top-model with bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "\n",
    "# Based on https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975\n",
    "# top_model.add(Flatten(input_shape=bottleneck_features_train.shape[1:]))\n",
    "# top_model.add(Dense(256, activation='relu'))\n",
    "# top_model.add(Dropout(0.5))\n",
    "\n",
    "# https://www.kaggle.com/abnera/transfer-learning-keras-xception-cnn\n",
    "# top_model.add(GlobalAveragePooling2D(input_shape=bottleneck_features_train.shape[1:]))\n",
    "\n",
    "# Based on https://www.depends-on-the-definition.com/transfer-learning-for-dog-breed-identification/\n",
    "top_model.add(BatchNormalization(input_shape=bottleneck_features_train.shape[1:]))\n",
    "top_model.add(GlobalAveragePooling2D())\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    " \n",
    "top_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "top_model.compile(optimizer=SGD(nesterov=True),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/bckenstler/CLR for Cyclical Learning Rate\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save weights of best training epoch: monitor either val_loss or val_acc\n",
    "STAMP = \"{}_top_model\".format(datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "top_model_weights_path = \"models/{}.h5\".format(STAMP)\n",
    "\n",
    "# Authors suggest setting step_size = (2-8) x (training iterations in epoch)\n",
    "step_size = 2000\n",
    "clr = CyclicLR(base_lr=0.008,\n",
    "               max_lr=0.03,\n",
    "               step_size=step_size,\n",
    "               mode='exp_range',\n",
    "               gamma=0.99994)\n",
    "\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(top_model_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1),\n",
    "    clr\n",
    "]\n",
    "\n",
    "top_model.fit(bottleneck_features_train, bottleneck_labels_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=top_model_epochs,\n",
    "              callbacks=callbacks_list,\n",
    "              validation_data=(bottleneck_features_valid, bottleneck_labels_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup data to flow from directory with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_xception,\n",
    "                                   rotation_range=45,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.25,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_folder,\n",
    "                                                    target_size=(INPUT_SIZE,INPUT_SIZE),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_xception)\n",
    "valid_generator = valid_datagen.flow_from_directory(directory=valid_folder,\n",
    "                                                    target_size=(INPUT_SIZE,INPUT_SIZE),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create and fine complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = xception.Xception(weights='imagenet', include_top=False, input_tensor=Input(shape=(299,299,3)))\n",
    "\n",
    "# top_model = Sequential()\n",
    "# top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "# top_model.add(Dense(256, activation='relu'))\n",
    "# top_model.add(Dropout(0.5))\n",
    "# top_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# Stack top_model on top\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "\n",
    "#for i, layer in enumerate(model.layers):\n",
    "#    print ('Layer #: {}, Name: {}'.format(i, layer.name))\n",
    "\n",
    "for layer in model.layers[:126]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[126:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(optimizer = SGD(lr=1e-4, momentum=0.9),\n",
    "              loss ='categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save weights of best training epoch: monitor either val_loss or val_acc\n",
    "STAMP = \"{}_complete_model\".format(datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "complete_model_weights_path = \"models/{}.h5\".format(STAMP)\n",
    "\n",
    "# Authors suggest setting step_size = (2-8) x (training iterations in epoch)\n",
    "step_size = 200\n",
    "clr = CyclicLR(base_lr=8*1e-5,\n",
    "               max_lr=4*1e-4,\n",
    "               step_size=step_size,\n",
    "               mode='exp_range',\n",
    "               gamma=0.99994)\n",
    "\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(complete_model_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1),\n",
    "    clr\n",
    "]\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                           steps_per_epoch=train_samples // BATCH_SIZE,\n",
    "                           epochs=complete_model_epochs,\n",
    "                           callbacks=callbacks_list,\n",
    "                           validation_data=valid_generator,\n",
    "                           validation_steps=valid_samples // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If testing with unlabeled samples ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = [f for f in listdir(test_folder) if isfile(join(test_folder, f))]\n",
    "x_test = np.zeros((len(test_imgs), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "\n",
    "for i, img_file in tqdm_notebook(enumerate(test_imgs)):\n",
    "    img = image.load_img(join(test_folder, img_file), target_size=(INPUT_SIZE,INPUT_SIZE))\n",
    "    img = image.img_to_array(img)\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_test[i] = x\n",
    "print('Test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))\n",
    "\n",
    "generator = valid_generator\n",
    "ypred = model.predict(x_test, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = test_imgs\n",
    "df = pd.DataFrame.from_dict(generator.class_indices, orient='index')\n",
    "class_list = df.sort_values(by=0).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_classes = np.argsort(ypred, axis=1)[:,-1] # or np.argmax(ypred, axis=1)\n",
    "pred2_classes = np.argsort(ypred, axis=1)[:,-2]\n",
    "pred3_classes = np.argsort(ypred, axis=1)[:,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_path, pred1, pred2, pred3 in zip(img_list,\n",
    "                                         [class_list[int(b)] for b in pred1_classes],\n",
    "                                         [class_list[int(b)] for b in pred2_classes],\n",
    "                                         [class_list[int(b)] for b in pred3_classes]):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    img = image.load_img(join(test_folder, img_path), target_size=(INPUT_SIZE,INPUT_SIZE))\n",
    "    img = image.img_to_array(img)\n",
    "    ax.imshow(img / 255.)\n",
    "    ax.text(10, 250, 'P1: %s' % pred1, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.text(10, 270, 'P2: %s' % pred2, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.text(10, 290, 'P3: %s' % pred3, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.axis('off')\n",
    "    plt.show()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If validating with (labeled samples) ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = valid_generator\n",
    "ypred = model.predict_generator(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = generator.filenames\n",
    "df = pd.DataFrame.from_dict(generator.class_indices, orient='index')\n",
    "class_list = df.sort_values(by=0).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = generator.classes\n",
    "pred1_classes = np.argsort(ypred, axis=1)[:,-1] # or np.argmax(ypred, axis=1)\n",
    "pred2_classes = np.argsort(ypred, axis=1)[:,-2]\n",
    "pred3_classes = np.argsort(ypred, axis=1)[:,-3]\n",
    "top1_error_idx = (true_classes != pred1_classes)\n",
    "top3_error_idx = (true_classes != pred1_classes) & (true_classes != pred2_classes) & (true_classes != pred3_classes)\n",
    "\n",
    "print (\"Of {} images tested, top1 accuracy: {:.2f}% ({} wrong) and top3 accuracy: {:.2f}% ({} wrong)\".format(\n",
    "        len(img_list),\n",
    "        (1-np.sum(top1_error_idx)/len(img_list))*100, np.sum(top1_error_idx),\n",
    "        (1-np.sum(top3_error_idx)/len(img_list))*100, np.sum(top3_error_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_idx = top3_error_idx\n",
    "\n",
    "for img_path, cat, pred1, pred2, pred3 in zip(list(compress(img_list, error_idx)),\n",
    "                                              [class_list[int(b)] for b in true_classes[error_idx]],\n",
    "                                              [class_list[int(b)] for b in pred1_classes[error_idx]],\n",
    "                                              [class_list[int(b)] for b in pred2_classes[error_idx]],\n",
    "                                              [class_list[int(b)] for b in pred3_classes[error_idx]]):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    img = image.load_img(join(valid_folder, img_path), target_size=(INPUT_SIZE,INPUT_SIZE))\n",
    "    img = image.img_to_array(img)\n",
    "    ax.imshow(img / 255.)\n",
    "    ax.text(10, 250, 'P1: %s' % pred1, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.text(10, 270, 'P2: %s' % pred2, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.text(10, 290, 'P3: %s' % pred3, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.text(10, 310, 'LABEL: %s' % cat, color='k', backgroundcolor='g', alpha=0.8)\n",
    "    ax.axis('off')\n",
    "    plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_p36",
   "language": "python",
   "name": "tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
